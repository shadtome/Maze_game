{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training area for agents in Maze Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cody/Documents/DataSciBC/Generative_AI/maze_game/TrainingGround\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import matplotlib.pyplot as plt\n",
    "import maze_generator.maze_dataset as md\n",
    "import numpy as np\n",
    "from DQN.training.basic import BaseTraining\n",
    "from DQN.agents.runner_agent import MazeRunnerAgent\n",
    "\n",
    "import DQN.models.base as base\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Mazes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = md.Maze_dataset(1,(3,3),maze_type = 'percolation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGwCAYAAAAXAEo1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASeUlEQVR4nO3db2xVd/3A8c9dGb0ddh0I7YSGhUQNNSQ1/MlkE7Jp0jjjXNUHi1kQHqghAnHhgYTgRGeWOpegDwgsKGFRQ7KYyNgDona6AhshGgJO4oTMLGFQECcOpK5la+/vwS82ItR2l9Lzaft6JU12zz339tOdhHe+95x7b6lSqVQCABK7pegBAGA4YgVAemIFQHpiBUB6YgVAemIFQHpiBUB6U4oe4EZMmzYtent7o6amJhobG4seB4D36Pz589Hf3x/lcjl6enqG3K80nt8UXFNTEwMDA0WPAcANuuWWW6K/v3/o+8dwllFXU1NT9AgAjILh/j0f17Hy0h/AxDDcv+fjOlYATA5iBUB6YgVAemIFQHpiBUB6YgVAeuP6EyxGahy/73nS6+3tHXafcrk8BpNwszjGE1upVBqV57GyAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECIL3CY7Vt27aYN29elMvlWLRoURw8eLDokQBIptBYPfvss/Hoo4/Gpk2b4ujRo7Fs2bJ44IEH4tSpU0WOBUAypUqlUinql999992xcOHC2L59++C2lpaWaG9vj46OjmEf39zcHGfOnBl2vwL/RG5Qb2/vsPuUy+UxmISbxTGe2Eql0oj2mzNnTpw+fXrI+wtbWV25ciWOHDkSbW1tV21va2uLQ4cOXfcxfX19cenSpcEfEQKYHAqL1Ztvvhn9/f3R1NR01fampqY4d+7cdR/T0dERDQ0Ngz/d3d1jMSoABSv8Aov/XiJWKpUhl40bN26MixcvDv7Mnj17LEYEoGBTivrFM2fOjJqammtWUefPn79mtfVvtbW1UVtbO3h7pK+FAjC+Fbaymjp1aixatCg6Ozuv2t7Z2Rn33HNPQVMBkFFhK6uIiPXr18eKFSti8eLFsXTp0tixY0ecOnUqVq9eXeRYACRTaKwefvjh+Pvf/x6PP/54nD17NhYsWBD79u2Lu+66q8ixAEim0PdZ3Sjvs5r4vAdn4nOMJ7Zx/z4rABgpsQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECIL0pRQ8wFnp7e4segSrV1dUNu8/bb789BpNwszjGjISVFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6U2KNwWXy+WiR6BKI3kzqOM7vjnGjISVFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpiRUA6YkVAOmJFQDpVRWrRx55JHbs2BEnT54c7XkA4BpVxep973tfbNmyJebPnx+zZ8+OL37xi/H000/Hn//859GeDwCiVKlUKtU++Ny5c9HV1RVdXV2xf//+OHnyZDQ2NsbZs2dHc8YhNTc3x5kzZ4bd7wb+RArW29s77D7lcnkMJuFmcYwntlKpNKL95syZE6dPnx7y/hs6Z1VfXx/Tp0+P6dOnxx133BFTpkyJO++880aeEgCuUVWsNmzYEB/72Mdi5syZ8c1vfjOuXLkSGzdujL/+9a9x9OjR0Z4RgEluSjUPeuqpp2LWrFmxefPmeOihh6KlpaWqX37gwIF46qmn4siRI3H27NnYs2dPtLe3V/VcAExcVa2sjh49Gps2bYrf/e53sXz58rjzzjvj4Ycfju3bt8err7464ufp6emJ1tbW2Lp1azVjADBJ3NAFFv/2hz/8IX74wx/Gz372sxgYGIj+/v73Pkip9J5XVi6wmPicfJ/4HOOJbbQusKjqZcCI/19d/ftKwIMHD8alS5fiox/9aNx///3VPuWw+vr6oq+vb/C2CAFMDlXFavr06XH58uVobW2N++67L77yla/E8uXL4/bbbx/t+a7S0dER3/nOd27q7wAgn6pi9dOf/nRM4vTfNm7cGOvXrx+83dLSEt3d3WM6AwBjr6pYfeYznxn879OnT0epVIo5c+aM2lBDqa2tjdra2sHbI30tFIDxraqrAQcGBuLxxx+PhoaGuOuuu2Lu3Llxxx13xHe/+90YGBgY7RkBmOSqWllt2rQpdu7cGd/73vfi3nvvjUqlEi+//HJ8+9vfjt7e3njiiSdG9DyXL1+O1157bfD266+/HseOHYsZM2bE3LlzqxkNgAmoqkvXZ8+eHU8//XR89rOfvWr73r1742tf+9qILiePiOjq6rru1YMrV66MZ555ZtjHu3R94nNZ88TnGE9shV66fuHChZg/f/412+fPnx8XLlwY8fPcd999QgLAsKo6ZzXUp05s3bo1Wltbb3goAPhPVX824Kc//el44YUXYunSpVEqleLQoUPxxhtvxL59+0Z7RgAmufe8snrnnXdi8+bN8etf/zo+97nPxVtvvRUXLlyIz3/+83HixIlYtmzZzZgTgEnsPa+sbr311jh+/HjMmjVrxFf9AcCNqOqc1Ze+9KXYuXPnaM8CANdV1TmrK1euxI9//OPo7OyMxYsXx7Rp0666f8uWLaMyHABEVBmr48ePx8KFCyMi4uTJk1fd5yOQABhtVcXqxRdfHO05AGBIVZ2zAoCxJFYApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApCdWAKQnVgCkJ1YApDel6AHGQm9vb9EjUKW6urph93n77bfHYBJuFseYkbCyAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgvUnxpuByuVz0CFRpJG8GdXzHN8eYkbCyAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECID2xAiA9sQIgPbECIL1CY9XR0RFLliyJ+vr6aGxsjPb29jhx4kSRIwGQUKGx2r9/f6xZsyYOHz4cnZ2d8e6770ZbW1v09PQUORYAyUwp8pf/8pe/vOr2rl27orGxMY4cORLLly+/Zv++vr7o6+sbvF2pVG76jAAUL9U5q4sXL0ZExIwZM657f0dHRzQ0NAz+dHd3j+V4ABSkVEmyPKlUKvHQQw/FP/7xjzh48OB19/nvlVVLS8uIgpXkT6QKvb29w+5TLpfHYBJuFsd4YiuVSiPab86cOXH69Okh7y/0ZcD/tHbt2njllVfipZdeGnKf2traqK2tHbw90v8JAIxvKWK1bt26eP755+PAgQPR3Nxc9DgAJFNorCqVSqxbty727NkTXV1dMW/evCLHASCpQmO1Zs2a2L17d+zduzfq6+vj3LlzERHR0NAQdXV1RY4GQCKFXmAx1DmnXbt2xapVq4Z9fHNzc5w5c2bY/VxgMX45+T7xOcYT24S4wEJEABiJVO+zAoDrESsA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANKbUvQAY6FUKhU9AgA3wMoKgPTECoD0xAqA9MQKgPTECoD0xAqA9MQKgPRKlUqlUvQQ1Zo6dWq88847RY8BwA269dZb48qVK0PeP65XVv39/UWPAMAoGO7f83H9CRblcjl6e3ujpqYmGhsbix6nEJVKJbq7u2P27Nk+qWMCcnwnNsc34vz589Hf3x/lcvl/7jeuXwYk4tKlS9HQ0BAXL16M22+/vehxGGWO78Tm+I7cuH4ZEIDJQawASE+sxrna2trYvHlz1NbWFj0KN4HjO7E5viPnnBUA6VlZAZCeWAGQnlgBkJ5YAZCeWI1j27Zti3nz5kW5XI5FixbFwYMHix6JUXLgwIF48MEHBz/Z4Lnnnit6JEZRR0dHLFmyJOrr66OxsTHa29vjxIkTRY+VmliNU88++2w8+uijsWnTpjh69GgsW7YsHnjggTh16lTRozEKenp6orW1NbZu3Vr0KNwE+/fvjzVr1sThw4ejs7Mz3n333Whra4uenp6iR0vLpevj1N133x0LFy6M7du3D25raWmJ9vb26OjoKHAyRlupVIo9e/ZEe3t70aNwk/ztb3+LxsbG2L9/fyxfvrzocVKyshqHrly5EkeOHIm2trartre1tcWhQ4cKmgqo1sWLFyMiYsaMGQVPkpdYjUNvvvlm9Pf3R1NT01Xbm5qa4ty5cwVNBVSjUqnE+vXr4+Mf/3gsWLCg6HHSGtdfETLZ/fdXClQqlUn7NQMwXq1duzZeeeWVeOmll4oeJTWxGodmzpwZNTU116yizp8/f81qC8hr3bp18fzzz8eBAweiubm56HFS8zLgODR16tRYtGhRdHZ2XrW9s7Mz7rnnnoKmAkaqUqnE2rVr4xe/+EX89re/jXnz5hU9UnpWVuPU+vXrY8WKFbF48eJYunRp7NixI06dOhWrV68uejRGweXLl+O1114bvP3666/HsWPHYsaMGTF37twCJ2M0rFmzJnbv3h179+6N+vr6wVdJGhoaoq6uruDpcnLp+ji2bdu2+P73vx9nz56NBQsWxA9+8AOXvU4QXV1dcf/991+zfeXKlfHMM8+M/UCMqqHOLe/atStWrVo1tsOME2IFQHrOWQGQnlgBkJ5YAZCeWAGQnlgBkJ5YAZCeWAGQnlgBkJ5YwTi2atUqX8rIpCBWAKQnVgCkJ1ZQsIGBgXjyySfjgx/8YNTW1sbcuXPjiSeeiIiIP/7xj/GJT3wi6urq4v3vf3989atfjcuXLxc8MYw9sYKCbdy4MZ588sl47LHH4k9/+lPs3r07mpqa4l//+ld86lOfiunTp8fvf//7+PnPfx4vvPBCrF27tuiRYcz51HUo0D//+c+YNWtWbN26Nb785S9fdd+PfvSj2LBhQ7zxxhsxbdq0iIjYt29fPPjgg9Hd3R1NTU2xatWqeOutt+K5554rYHoYO1ZWUKBXX301+vr64pOf/OR172ttbR0MVUTEvffeGwMDA3HixImxHBMKJ1ZQoP/1rbCVSmXIL+kbajtMVGIFBfrQhz4UdXV18Zvf/Oaa+z7ykY/EsWPHoqenZ3Dbyy+/HLfcckt8+MMfHssxoXBiBQUql8uxYcOG+MY3vhE/+clP4i9/+UscPnw4du7cGY888kiUy+VYuXJlHD9+PF588cVYt25drFixIpqamooeHcbUlKIHgMnuscceiylTpsS3vvWt6O7ujg984AOxevXquO222+JXv/pVfP3rX48lS5bEbbfdFl/4whdiy5YtRY8MY87VgACk52VAANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDSEysA0hMrANITKwDS+z8Y5B9FSBNopgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of the maze\n",
    "dataset.show_maze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the agents\n",
    "n_agents = 2\n",
    "vision = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agents': <Maze_env.reward_functions.maze_runner.MazeRunnerRewardsFun object at 0x7daa3c2d3d10>}\n",
      "----------------------------------\n",
      "Basic epsilon decay scheduler:\n",
      "Start epsilon: 1\n",
      "End epsilon: 0.05\n",
      "Decay total: 200000\n",
      "Decay rate: 0.0014903642610661133\n",
      "\n",
      "------------------------------\n",
      "Group 0: Learning rate = 0.0005\n",
      "--------------------------------------\n",
      "Basis learning rate scheduler:\n",
      "Step size: 5000\n",
      "Gamma: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cody/miniconda3/envs/GameRFL/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:245: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "\n",
      "frame [10000:320000] with loss 19.486249923706055\n",
      "Learning rate : 0.0005\n",
      "Epsilon: 0.9999850214508118\n",
      "Current Score: {'agents': 0.12500000000000008}\n",
      "cumulative reward: {'agents': [-309.98333333333335, -259.7055555555555]}\n",
      "cumulative reward: {'agents': [-212.5, -209.2425925925926]}\n",
      "cumulative reward: {'agents': [-183.47592592592594, -119.40185185185186]}\n",
      "cumulative reward: {'agents': [-262.5, 67.79444444444447]}\n",
      "cumulative reward: {'agents': [-183.47592592592594, -212.5]}\n",
      "cumulative reward: {'agents': [-83.14629629629628, -86.1648148148148]}\n",
      "cumulative reward: {'agents': [68.80555555555557, -144.17037037037036]}\n",
      "cumulative reward: {'agents': [-259.7055555555555, 75.85555555555557]}\n",
      "cumulative reward: {'agents': [-262.5, -162.5]}\n",
      "cumulative reward: {'agents': [-162.5, -209.2425925925926]}\n",
      "----------------------------------\n",
      "\n",
      "frame [20000:320000] with loss 7.122337341308594\n",
      "Learning rate : 0.00048019999999999996\n",
      "Epsilon: 0.8608787644236698\n",
      "Current Score: {'agents': 0.11300000000000009}\n",
      "cumulative reward: {'agents': [-253.19814814814814, -162.5]}\n",
      "cumulative reward: {'agents': [-259.7055555555555, -212.5]}\n",
      "cumulative reward: {'agents': [-139.98333333333335, 75.78333333333335]}\n",
      "cumulative reward: {'agents': [67.79444444444447, -303.93888888888887]}\n",
      "cumulative reward: {'agents': [-119.40185185185186, -232.4574074074074]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# --- trainer of the agent --- #\u001b[39;00m\n\u001b[1;32m     12\u001b[0m train \u001b[38;5;241m=\u001b[39m BaseTraining(name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTestRunner\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m                               maze_dataset \u001b[38;5;241m=\u001b[39m dataset,\n\u001b[1;32m     14\u001b[0m                               maze_agent \u001b[38;5;241m=\u001b[39m maze_agent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m                               frame_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m,\n\u001b[1;32m     39\u001b[0m                               )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mpeak\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:559\u001b[0m, in \u001b[0;36mBaseTraining.train\u001b[0;34m(self, test_agent, peak)\u001b[0m\n\u001b[1;32m    556\u001b[0m         start_updating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_of_objects:\n\u001b[0;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_networks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_updating\u001b[49m\u001b[43m,\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m     frame\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    563\u001b[0m env\u001b[38;5;241m.\u001b[39mclose() \n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:415\u001b[0m, in \u001b[0;36mBaseTraining.update_networks\u001b[0;34m(self, update_start, frame, obj_type)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer[obj_type]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# --- compute loss --- #\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m loss,action_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# --- save losses --- #\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses[obj_type]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:290\u001b[0m, in \u001b[0;36mBaseTraining.compute_loss\u001b[0;34m(self, frame, obj_type)\u001b[0m\n\u001b[1;32m    283\u001b[0m local_s,global_s, actions,next_local_s,next_global_s, rewards, terminated,info, weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_replay(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,obj_type)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# We need to find $Q^*(s,a) \\approx r + \\gamma * Q(s', max_{a'} Q'(s',a'))\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Where (s,a,r,s') is from the replay buffer, Q is the policy net, Q' is the target net\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# --- get Q(s,a) for each action --- #\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplyPolicyQ_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43mglobal_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m avg_q_values \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents\u001b[38;5;241m.\u001b[39mn_actions):\n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:326\u001b[0m, in \u001b[0;36mBaseTraining.applyPolicyQ_fun\u001b[0;34m(self, local_s, global_s, info, obj_type)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapplyPolicyQ_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m,local_s,global_s,info,obj_type):\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43mglobal_s\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/models/base.py:114\u001b[0m, in \u001b[0;36mCNN_version1.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[0;32m--> 114\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNN_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x,y),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    117\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_function(combined)\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "# --- Agents for the Hunger Games --- #\n",
    "maze_agent =MazeRunnerAgent({'agents':base.CNN_version1},\n",
    "                               vision={'agents':vision},\n",
    "                               action_type='cardinal',\n",
    "                               dist_paradigm='path'\n",
    "                               )\n",
    "\n",
    "# --- trainer of the agent --- #\n",
    "train = BaseTraining(name = 'TestRunner',\n",
    "                              maze_dataset = dataset,\n",
    "                              maze_agent = maze_agent,\n",
    "                              len_game=30,\n",
    "                              n_objects={'agents':n_agents},\n",
    "                              final_epsilon = 0.05,\n",
    "                              gamma = 0.99,\n",
    "                              tau = 0.0001,\n",
    "                               batch_size = 64,\n",
    "                              n_frames = 500000,\n",
    "                              lr = 0.0005,\n",
    "                              lr_heads=0.0005,\n",
    "                              lr_step_size=5000,\n",
    "                              lr_head_step_size=2500,\n",
    "                              lr_gamma = 0.98,\n",
    "                              lr_head_gamma = 0.98,\n",
    "                              l2_regular=0.01,\n",
    "                              replay_buffer_size=200000,\n",
    "                              replay_buffer_min_perc=0.1,\n",
    "                              target_update=5000,\n",
    "                              policy_update=1,\n",
    "                              lambda_entropy=0.1,\n",
    "                              beta = 0.4,\n",
    "                              alpha = 0.6,\n",
    "                              decay_total = 200000,\n",
    "                              per = True,\n",
    "                              frame_mult=1.5,\n",
    "                              )\n",
    "train.train(test_agent=True,peak=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cody/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:631: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data = scores_df, x ='frame',y = 'score',ax = axe[1][1],palette='tab10')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/seaborn/_base.py:1768\u001b[0m, in \u001b[0;36mcategorical_order\u001b[0;34m(vector, order)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1768\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[38;5;241m.\u001b[39mcategories\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:2898\u001b[0m, in \u001b[0;36mCategoricalAccessor.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2898\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:2907\u001b[0m, in \u001b[0;36mCategoricalAccessor._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype):\n\u001b[0;32m-> 2907\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .cat accessor with a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .cat accessor with a 'category' dtype",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:683\u001b[0m, in \u001b[0;36mBaseTraining.results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_of_objects:\n\u001b[1;32m    681\u001b[0m     fig, axe \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_objects[obj_type]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m     obj_fd_original \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(fd_original,obj_type)\n\u001b[1;32m    686\u001b[0m     obj_fd_best \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(fd_best,obj_type)\n",
      "File \u001b[0;32m~/Documents/DataSciBC/Generative_AI/maze_game/DQN/training/basic.py:631\u001b[0m, in \u001b[0;36mBaseTraining.update_plots\u001b[0;34m(self, frame, fig, axe, obj_type)\u001b[0m\n\u001b[1;32m    629\u001b[0m     scores_data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m: frame, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m:score})\n\u001b[1;32m    630\u001b[0m scores_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scores_data)\n\u001b[0;32m--> 631\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscores_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maxe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtab10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_objects[obj_type]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;66;03m# Lets find a moving average of the scores\u001b[39;00m\n\u001b[1;32m    635\u001b[0m       \u001b[38;5;66;03m# Adjust based on how much smoothing you want\u001b[39;00m\n\u001b[1;32m    636\u001b[0m     scores_series \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcum_reward[obj_type\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/seaborn/relational.py:508\u001b[0m, in \u001b[0;36mlineplot\u001b[0;34m(data, x, y, hue, size, style, units, weights, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mhas_xy_data:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ax\n\u001b[0;32m--> 508\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Other functions have color as an explicit param,\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;66;03m# and we should probably do that here too\u001b[39;00m\n\u001b[1;32m    512\u001b[0m color \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/seaborn/_base.py:1134\u001b[0m, in \u001b[0;36mVectorPlotter._attach\u001b[0;34m(self, obj, allowed_types, log_scale)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m                 order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1134\u001b[0m             seed_data \u001b[38;5;241m=\u001b[39m \u001b[43mcategorical_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         converter\u001b[38;5;241m.\u001b[39mupdate_units(seed_data)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# -- Set numerical axis scales\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# First unpack the log_scale argument\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/seaborn/_base.py:1771\u001b[0m, in \u001b[0;36mcategorical_order\u001b[0;34m(vector, order)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     order \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m-> 1771\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable_type(vector) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1774\u001b[0m         order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(order)\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/series.py:2407\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GameRFL/lib/python3.12/site-packages/pandas/core/algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7248\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "train.save()\n",
    "train.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cody/miniconda3/envs/GameRFL/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:245: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agents': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.agents.test_agent(dataset,n_episodes=1000,len_game=15,num_objects={'agents':n_agents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cody/miniconda3/envs/GameRFL/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:245: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative reward: {'agents': [22.58703703703704]}\n",
      "cumulative reward: {'agents': [11.961111111111112]}\n",
      "cumulative reward: {'agents': [-120.24074074074073]}\n",
      "cumulative reward: {'agents': [14.811111111111112]}\n",
      "cumulative reward: {'agents': [-195.83333333333331]}\n",
      "cumulative reward: {'agents': [12.033333333333335]}\n",
      "cumulative reward: {'agents': [-176.64999999999998]}\n",
      "cumulative reward: {'agents': [22.65925925925926]}\n",
      "cumulative reward: {'agents': [17.57777777777778]}\n",
      "cumulative reward: {'agents': [-195.83333333333331]}\n",
      "cumulative reward: {'agents': [-176.64999999999998]}\n",
      "cumulative reward: {'agents': [-176.64999999999998]}\n",
      "cumulative reward: {'agents': [-105.99999999999999]}\n",
      "cumulative reward: {'agents': [22.65925925925926]}\n",
      "cumulative reward: {'agents': [25.425925925925927]}\n",
      "cumulative reward: {'agents': [25.425925925925927]}\n",
      "cumulative reward: {'agents': [-146.27777777777777]}\n",
      "cumulative reward: {'agents': [6.362962962962964]}\n",
      "cumulative reward: {'agents': [22.65925925925926]}\n",
      "cumulative reward: {'agents': [-176.64999999999998]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train.agents.run_agent(dataset[0],num_objects={'agents':n_agents},n_episodes=20,len_game=15,epsilon=0,init_pos={})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GameRFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
